```{r}
#loading packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
library(sjPlot)
```
```{r}
#loading dataframe
raw_data <- as.data.frame(irltim)
```

```{r}
view(cleaned_data)
```

```{r}
any(is.na(cleaned_data))
```

```{r}
sum(is.na(cleaned_data))
```


#Data modelling 
#linear mixed model(with year=2015)

```{r}
df_2015<-cleaned_data%>%
  filter(Year==2015)%>%
  mutate(
    Gender=factor(Gender,levels=c("GIRL","BOY"),ordered=TRUE),
    Parent_Educ=factor(Parent_Educ,levels=c("less than ISCED2",
                                          "ISCED2",
                                          "ISCED3","ISCED4","ISCED6",
                                          "ISCED7 or 8"),ordered= TRUE),
    Parent_Support=factor(Parent_Support,levels=c("LOW","MEDIUM","HIGH",
                                                  "VERY HIGH"),ordered=TRUE),
    Computer_Access=factor(Computer_Access,levels=c("YES","NO"),ordered=TRUE),
    Location = factor(Location,levels=c("Urban","Suburban",
                                        "Large Town/City",
                                        "Small Town/Village",
                                        "Remote Rural"),ordered= TRUE),
    Book_Availability = factor(Book_Availability,levels=c("Few","Moderate","Good",
                                                          "Very Good",
                                                           "Excellent"),
                                                            ordered=TRUE),
    Teacher_Shortage =factor(Teacher_Shortage,levels=c("None","Low","Moderate",
                                                       "High"),ordered=TRUE),
    Percent_Affluent =factor(Percent_Affluent,levels=c("Low","Moderate",
                                                       "High","Excellent"),
                                                             ordered=TRUE),
    Percent_Disadvantaged=factor(Percent_Disadvantaged,
                                 levels=c("Low", "Moderate","High","Severe"),
                                                                 ordered=TRUE)
)

lmm_model1<- lmer(Scores ~ Gender + Parent_Educ + Parent_Support + Computer_Access +
                    Location + Book_Availability + Teacher_Shortage + Percent_Disadvantaged
                    +(1 | School_Id), data = df_2015)

sjPlot::tab_model(lmm_model1,
                  show.ci = FALSE, show.aic = TRUE,
                  show.se = TRUE,
                  show.stat = TRUE,
                  show.obs = FALSE)

```


**Interpretation**

*Random effects*
*B*Baseline scores definition*B*:-
It is the predicted average score for a given random effect(here School_Id) 
before we consider the fixed effects.(i.e other predictors).
Here the model assumes each school has its own baseline score
(i.e its own average starting score)

A variance of 362.3 for the random intercept of school_id indicates the value 
by which the average scores vary across the schools.So therefore schools differ 
by a std.dev of 19.03 points from their baseline scores.
basically the variance and the std dev shows the spread of these baseline scores 
across schools.This helps to account for the school-level differences
in average performance.

Also, we can interpret that the total variance = residual variance+ random effect variance
                                               = 3027.9+362.3 =3390.2
                  So the variance partition coefficient(ICC)= 362.3/3390.2= 0.107
                                                            ~10.7%
  That is about 11% of the total variance in math scores is due to the differences between schools.

*Fixed effects*
These are the main effects which we are estimating in the model that represents
the average effect of each predictor with respect to the scores. 

Intercept in the model that is 517.9353 is actually the baseline average 
math score for the reference group.
Reference group is formed by first level of each ordered categorical variables.
Hence, the average math score can be interpreted w.r.t the reference group.

The rest of the predictors having labels like L,Q,C,^4 indicates different trends 
such as linear, quadratic, cubic, quartic etc since they are ordered factors and 
R uses polynomial contrasts to test how the response variable changes across these 
ordered levels.

**Key insights**
Gender.L :- here boys have on average, 8.8 points higher scores than girls
(which is the reference group).
Book_Availability.L :- has a very strong positive linear effect (58.32) on math 
scores which indicates more accessibility to books resulted in higher scores.
Percent_disadvantaged.L :- has a significant negative linear effect(-28.17) 
on math scores which tells that as disadvantage level increases, their scores 
also see a drop by 28 points.
Parent_Educ.L:- here it shows as the parent education level increases, scores 
decreases linearly by 18 points(-18.23) which is an unexpected result.

Other predictors such as Teacher Shortage, Percent_Affluent,Location, 
Parent_Support indicates weaker or insignificant effects on 
math scores(compared to t-value and estimates)

*Model Diagnostics*
```{r}
plot(lmm_model1)
```
```{r}
qqnorm(resid(lmm_model1))
qqline(resid(lmm_model1))
```
```{r}
cooksd1 <- cooks.distance(lmm_model1)
plot(cooksd1, main = "Cook's Distance", pch = "*", cex = 1.5)
abline(h = 4/length(cooksd1), col = "red") 
influential1 <- as.numeric(names(cooksd1)[(cooksd1 > (4/length(cooksd1)))])
df_Year[influential1, ]
```



**Interpretation**
The Residual vs Fitted model suggests that there is a good amount of linearity 
and homoscedasticity as the residuals are evenly scattered around 0 across the 
range of fitted scores.There is also no clear pattern like a funnel_shape or curve.
Normal Q-Q plots shows that most of the points lie along the diagonal line indicating 
the residuals are approximately normally distributed.Only slight deviations at the tails,
indicating skewness is seen.
Cook's Distance Plot suggest that most of the points have lower cook's distance, 
indicating that no single observation has a potential influence on the model.
That is overall there is no sign of extreme influential points in the model.



#linear mixed model(with year=2019)
```{r}
df_2019<-cleaned_data%>%
  filter(Year==2019)%>%
  mutate(
    Gender=factor(Gender,levels=c("GIRL","BOY"),ordered=TRUE),
    Parent_Educ=factor(Parent_Educ,levels=c("less than ISCED2",
                                            "ISCED2",
                                            "ISCED3","ISCED4","ISCED6",
                                            "ISCED7 or 8"),ordered= TRUE),
    Parent_Support=factor(Parent_Support,levels=c("LOW","MEDIUM","HIGH",
                                                  "VERY HIGH"),ordered=TRUE),
    Computer_Access=factor(Computer_Access,levels=c("YES","NO"),ordered=TRUE),
    Location = factor(Location,levels=c("Urban","Suburban",
                                        "Large Town/City",
                                        "Small Town/Village",
                                        "Remote Rural"),ordered= TRUE),
    Book_Availability = factor(Book_Availability,
                               levels=c("Few","Moderate","Good",
                                        "Very Good","Excellent"),
                                         ordered=TRUE),
    Teacher_Shortage =factor(Teacher_Shortage,levels=c("None","Low",
                                                       "Moderate","High"),
                                                          ordered=TRUE),
    Percent_Affluent =factor(Percent_Affluent,levels=c("Low","Moderate",
                                                       "High","Excellent"),
                                                          ordered=TRUE),
    Percent_Disadvantaged=factor(Percent_Disadvantaged,
                                 levels=c("Low","Moderate",
                                            "High","Severe"),
                                              ordered=TRUE)
  )

lmm_model2<-lmer(Scores ~ Gender+ Parent_Educ+ Parent_Support+Computer_Access+
                   Location + Book_Availability + Teacher_Shortage + Percent_Disadvantaged 
                 +(1 | School_Id),
                 data = df_2019)

sjPlot::tab_model(lmm_model2,
                  show.ci = FALSE, show.aic = TRUE,
                  show.se = TRUE,
                  show.stat = TRUE,
                  show.obs = FALSE)
```



**Interpretation**
A variance of 247.7 for the random intercept of school_id indicates the value by 
which the average scores vary across the schools.So therefore schools differ by 
a std.dev of 19.03 points from their baseline scores.
Intercept in the model that is 516.05336 is actually the baseline average math 
score for the reference group

**Key insights**
Gender.L:- Here also Boys score 4.5points higher than the girls on average.
Parent_Educ.L:- Implies as level increases, the math scores are decreased by 
22points.(linear trend)
Parent_Support.L:- Higher support is associated with higher scores(21.85).
Book_Availability:- Indicates higher positive effect of (57 points) when increasing levels.
Percent_Disadvantaged:- More disadvantaged levels leads to lower scores(-14.06).


*Model Diagnostics*
```{r}
plot(lmm_model2)
```

```{r}
qqnorm(resid(lmm_model2))
qqline(resid(lmm_model2))
```
```{r}
cooksd2 <- cooks.distance(lmm_model2)
plot(cooksd2, main = "Cook's Distance", pch = "*", cex = 1.5)
abline(h = 4/length(cooksd2), col = "red") 
influential2 <- as.numeric(names(cooksd2)[(cooksd2 > (4/length(cooksd2)))])
df_2019[influential2, ]
```
**Interpretation**
The Residual vs Fitted model suggests that there is a good amount of linearity 
and homoscedasticity as the residuals are evenly scattered around 0 across 
the range of fitted scores.There is also no clear pattern like a funnel_shape or curve.
Normal Q-Q plots shows that most of the points lie along the diagonal line indicating 
the residuals are approximately normally distributed.Only slight deviations at the tails, 
indicating skewness is seen.
Cook's Distance Plot suggest that most of the points have lower cook's distance, 
indicating that no single observation has a potential influence on the model.
That is overall there is no sign of extreme influential points in the model.



#linear mixed model(both years)
```{r}
df_Year<-cleaned_data%>%
   mutate(
    Year=factor(Year,levels=c("2015","2019"),ordered=TRUE),
    Gender=factor(Gender,levels=c("GIRL","BOY"),ordered=TRUE),
    Parent_Educ=factor(Parent_Educ,levels=c("less than ISCED2",
                                          "ISCED2",
                                          "ISCED3","ISCED4","ISCED6",
                                          "ISCED7 or 8"),ordered= TRUE),
    Parent_Support=factor(Parent_Support,levels=c("LOW","MEDIUM","HIGH",
                                                  "VERY HIGH"),ordered=TRUE),
    Computer_Access=factor(Computer_Access,levels=c("YES","NO"),ordered=TRUE),
    Location = factor(Location,levels=c("Urban","Suburban",
                                        "Large Town/City",
                                        "Small Town/Village",
                                        "Remote Rural"),ordered= TRUE),
    Book_Availability = factor(Book_Availability,
                               levels=c("Few","Moderate","Good",
                                        "Very Good","Excellent"),
                                          ordered=TRUE),
    Teacher_Shortage =factor(Teacher_Shortage,levels=c("None","Low","Moderate",
                                                       "High"),ordered=TRUE),
    Percent_Affluent =factor(Percent_Affluent,levels=c("Low","Moderate",
                                                       "High","Excellent"),
                                                             ordered=TRUE),
    Percent_Disadvantaged=factor(Percent_Disadvantaged,
                                 levels=c("Low", "Moderate","High","Severe"),
                                                                 ordered=TRUE)
)

lmm_model3<-lmer(Scores ~ Gender+ Parent_Educ+ Parent_Support+ Computer_Access+
                   Location + Book_Availability + Teacher_Shortage + Percent_Disadvantaged +
                   Year+ (1 | School_Id:Year), data = df_Year)

sjPlot::tab_model(lmm_model3,
                  show.ci = FALSE, show.aic = TRUE,
                  show.se = TRUE,
                  show.stat = TRUE,
                  show.obs = FALSE)
```



**Interpretation**
Here our model takes the random effect of each School-Year combination, 
It allows to have its own baseline average math scores.

*Random effects*
There are unique 253 School-Year combinations and the random intercept variance
measures how much average math scores differ across these 253 unique groups.
That is on average, schools differ from the overall baseline by about 17.28 points.
Students within the same school-year typically differ from their school's Baseline 
by about 55 points.

So here variance partition coefficient(ICC)=298.7/3346=0.089
                                                     ~8.9%
    That is 8.9% of total variance in math scores is due to the differences between 
    schools and rest of the variation comes from individual student differences.

*Fixed effects & Key insights*
The intercept 520.1146 is the average math scores for the reference student group.

Gender.L:- that is Boys score on average 6.56 points higher than girls.
Parent_Educ.L:- This indicates as education level increases, scores decreases by 
20 points linearly. Also indicates a strong negative linear trend(significant)
Book_availability:- Indicates a strong positive linear effect on scores by 
57.74 points on scores which indicates more access to books result in higher scores.
Percent_Disadvantaged:- strong negative linear effect which tells as disadvantage 
level increases,it results in lower scores(-20.97).
Year.L:- Doesn't really show any significant difference in average scores 
between 2015 and 2019.
Percent_Affluent:- indicates slightly higher scores as result of increase in affluent levels.

*Model Diagnostics*
```{r}
plot(lmm_model3)
```

```{r}
qqnorm(resid(lmm_model3))
qqline(resid(lmm_model3))
```
```{r}
cooksd3 <- cooks.distance(lmm_model3)
plot(cooksd3, main = "Cook's Distance", pch = "*", cex = 1.5)
abline(h = 4/length(cooksd3), col = "red") 
influential3 <- as.numeric(names(cooksd3)[(cooksd3 > (4/length(cooksd3)))])
df_Year[influential3, ]
```
**Interpretation of Plots(lmm_model3)**
The Residual vs Fitted model suggests that there is a good amount of linearity 
and homoscedasticity as the residuals are evenly scattered around 0 across the 
range of fitted scores.There is also no clear pattern like a funnel_shape or curve.
Normal Q-Q plots shows that most of the points lie along the diagonal line indicating the 
residuals are approximately normally distributed.Only slight deviations at the tails, indicating skewness is seen.
Cook's Distance Plot suggest that most of the points have lower cook's distance, indicating that no single observation has a potential influence on the model.That is overall there is no sign of influential outliers in this model.(In lmm, influenential points might also be due to group differences in the local-level)


#Random effects plot
```{r}
library(lattice)
re <- ranef(lmm_model3, condVar=TRUE)
re_df <- as.data.frame(re$`School_Id:Year`)
re_df$School_Year <- rownames(re$`School_Id:Year`)
re_df <- re_df[order(re_df$`(Intercept)`), ]
dotplot(
  reorder(School_Year, `(Intercept)`) ~ `(Intercept)`,
  data = re_df,
  main = "Random Intercepts by School-Year",
  xlab = "Random Intercept",
  scales = list(y = list(cex=0.4)),
  col.line = "Grey",
  col = "blue",
  aspect = 1.5  
)
```
*Interpretation*
Here the X-axis gives the random intercept estimates for that school-year group
and Y-axis gives each school-year combination.The blue dots represents the estimated random intercepts for each group.Horizontal lines represents confidence intervals for random intercepts.

Left side indicates negative values which means schools having negative random intercepts, indicates that their average math scores are lower than the overall baseline.
Right side indicates positive values which means Schools with higher-than-average baseline math scores.
Centre(near0)indicates schools close to the average baseline where average math scores are similar to the overall baseline scores.
Flatter ends indicates a few schools might have higher or lower average math scores.

**Key insights*
Most schools are clustered around 0 showing their average math scores are similar after accounting for fixed effects.
A few schools stand out having much higher or lower random intercepts.
The spread of random intercepts tells how much school average scores vary after accounting for fixed effects.

This plot shows how schools differ in their average math scores above or below the grand average where most of the schools are close to the average.

*Checking Multicollinearity*
```{r}
library(car)
vif(lmm_model1)
vif(lmm_model2)
vif(lmm_model3)
```
*Interpretation*
Moderate level of multicollinearity exists but very less.
















