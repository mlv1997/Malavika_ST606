```{r}
#loading packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
library(sjPlot)
library(rsample)
library(ranger)
```

```{r}
#loading dataframe
raw_data <- as.data.frame(irltim)
```

```{r}
view(cleaned_data)
```


#Splitting into train and test data 
```{r}
set.seed(123)


df_Year <- cleaned_data%>%
   mutate(
    School_Id=factor(School_Id),
    Year=factor(Year,levels=c("2015","2019"),ordered=TRUE),
    Gender=factor(Gender,levels=c("GIRL","BOY"),ordered=TRUE),
    Parent_Educ=factor(Parent_Educ,levels=c("less than ISCED2",
                                          "ISCED2",
                                          "ISCED3","ISCED4","ISCED6",
                                          "ISCED7 or 8"),ordered= TRUE),
    Parent_Support=factor(Parent_Support,levels=c("LOW","MEDIUM","HIGH",
                                                  "VERY HIGH"),ordered=TRUE),
    Computer_Access=factor(Computer_Access,levels=c("YES","NO"),ordered=TRUE),
    Location = factor(Location,levels=c("Urban","Suburban",
                                        "Large Town/City",
                                        "Small Town/Village",
                                        "Remote Rural"),ordered= TRUE),
    Book_Availability = factor(Book_Availability,
                               levels=c("Few","Moderate","Good",
                                        "Very Good","Excellent"),
                                          ordered=TRUE),
    Teacher_Shortage =factor(Teacher_Shortage,levels=c("None","Low","Moderate",
                                                       "High"),ordered=TRUE),
    Percent_Affluent =factor(Percent_Affluent,levels=c("Low","Moderate",
                                                       "High","Excellent"),
                                                             ordered=TRUE),
    Percent_Disadvantaged=factor(Percent_Disadvantaged,
                                 levels=c("Low", "Moderate","High","Severe"),
                                                                 ordered=TRUE))


school_ids_both_years <- df_Year %>%
  group_by(School_Id) %>%
  summarise(n_years = n_distinct(Year)) %>%
  filter(n_years == 2) %>%
  pull(School_Id)
```


```{r}
train_school_ids <- sample(school_ids_both_years, 
                           size = round(0.8 * length(school_ids_both_years)))


train_data <- df_Year %>% filter(School_Id %in% train_school_ids)
test_data  <- df_Year %>% filter(!(School_Id %in% train_school_ids))
```


#lmm model of both years
```{r}
lmm_model31<-lmer(Scores ~ Gender+ Parent_Support+ Parent_Educ+ Computer_Access+
                   Location + Book_Availability + Teacher_Shortage + Percent_Disadvantaged
                  + Year+ (1 | School_Id:Year), 
                  data = train_data)

sjPlot::tab_model(lmm_model31,
                  show.ci = FALSE, show.aic = TRUE,
                  show.se = TRUE,
                  show.stat = TRUE,
                  show.obs = FALSE)
```

#Random forest regresssion model
```{r}
rf_ranger <- ranger(
  formula = Scores ~ Gender + Parent_Educ + Parent_Support + Computer_Access +
            Location + Book_Availability + Teacher_Shortage +
            Percent_Disadvantaged + Year,
  data = train_data,
  num.trees = 500,
  importance = "impurity"
)
rf_ranger
```


#Comparison of both lmm and random forest models
```{r}
pred_scores <- predict(rf_ranger, newdata = test_data)
rmse <- sqrt(mean((pred_scores - test_data$Scores)^2))
rmse
rsq <- 1 - sum((pred_scores - test_data$Scores)^2) / 
           sum((mean(train_data$Scores) - test_data$Scores)^2)
rsq
```
```{r}
pred_scores <- predict(lmm_model31, newdata = test_data)
rmse <- sqrt(mean((pred_scores - test_data$Scores)^2))
rmse
rsq <- 1 - sum((pred_scores - test_data$Scores)^2) / 
           sum((mean(train_data$Scores) - test_data$Scores)^2)
rsq
```
